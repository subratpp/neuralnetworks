{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multilayernn import * #Import from own library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Processing and One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"datasets/mnist_train.csv\") #read data from file\n",
    "\n",
    "#separating labels and pixels\n",
    "train_labels=np.array(train.loc[:,'label'])\n",
    "train_data=np.array(train.loc[:,train.columns!='label'])\n",
    "#The characteristics of MNIST data pixels = 784 samples = 42000 classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to onehot encoding\n",
    "pixels = 784\n",
    "samples = len(train_labels)\n",
    "classes = 10\n",
    "train_data = train_data.T #Transpose the matrix: where each column is a sample\n",
    "train_label=np.zeros((classes, samples))\n",
    "\n",
    "for col in range (samples):\n",
    "    train_label[train_labels[col],col]=1\n",
    "\n",
    "#Scaling Down of dataset\n",
    "train_data = train_data/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training of Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypermeters:\n",
    "1. Tune the right weights as improper weights will cause exploding outputs\n",
    "2. Tune the learning rate and gamma\n",
    "3. Tune the number of epoch to be trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Mulit Layer Network\n",
    "nodes_per_layer = [784, 500, 200, 80, 10] #nodes in each layer of neural network\n",
    "mnist_nn = deepNN(nodes_per_layer, learning_rate = 0.3, gamma = 0.7, epoch=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the network\n",
    "mnist_nn.train_model(train_data, train_label, train_labels, verbose = True, filename=\"accuracy/mnist/mnistdata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Testing of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data preprocessing\n",
    "test = pd.read_csv(\"datasets/mnist_test.csv\") #read data from file\n",
    "\n",
    "#separating labels and pixels\n",
    "test_labels=np.array(test.loc[:,'label'])\n",
    "test_data=np.array(test.loc[:,test.columns!='label'])\n",
    "#The characteristics of MNIST data pixels = 784 samples = 42000 classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to onehot encoding\n",
    "pixels = 784\n",
    "samples = len(test_labels)\n",
    "classes = 10\n",
    "test_data = test_data.T #Transpose the matrix: where each column is a sample\n",
    "test_label=np.zeros((classes, samples))\n",
    "\n",
    "for col in range (samples):\n",
    "    test_label[test_labels[col],col]=1\n",
    "\n",
    "#Scaling Down of dataset\n",
    "test_data = test_data/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_error, test_accuracy = mnist_nn.test_model( test_data, test_label, test_labels, filename=\"accuracy/mnist/mnistdata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "Check accuracy folder for all the error and accuracy data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle: Test and Compute Accuracy for Submission\n",
    "For submission to the Kaggle the kaggle test data needs to be passed through the model.\n",
    "The following code will generate the \"sample_submission.csv\" for the Kaggle MNIST.\n",
    "\n",
    "**Uncomment the Following for Kaggle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data= pd.read_csv(\"datasets/kaggle/mnist_test.csv\") #This generated cvs file which can be submitted to the Kaggle\n",
    "# test_data=np.array(test_data) #separating labels and pixels\n",
    "\n",
    "# #Preprocess data for the model\n",
    "# test_data = test_data.T #Transpose the matrix: where each column is a sample\n",
    "# test_data = test_data/255 #scale the data to range 1\n",
    "\n",
    "# #Test the data for the model\n",
    "# Y_hat, cache = mnist_nn.forward_propagation(test_data)\n",
    "# Y_predicted = np.argmax(Y_hat, axis=0)\n",
    "\n",
    "# #Create submission ready data\n",
    "# df = pd.DataFrame(Y_predicted, columns = [\"Label\"]) \n",
    "# df.index.name = 'ImageId'\n",
    "# df.index += 1 \n",
    "# df.to_csv('kaggle_submission/sample_submission.csv', index = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
